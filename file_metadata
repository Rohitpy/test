import logging
import json
from typing import Dict, Any, List
import pandas as pd
from app.models.llm.llm_service import LLMService
from app.models.database.db_manager import TeradataManager

logging.basicConfig(level=logging.INFO,
                   format='%(asctime)s - %(levelname)s - %(message)s')

# Hardcoded schema definition
DOCUMENT_SCHEMA = {
    "table_name": "DO_DOCUMENTS",
    "columns": [
        {"name": "DOC_ID", "type": "INTEGER", "description": "Unique identifier for the document"},
        {"name": "TITLE", "type": "VARCHAR(255)", "description": "Document title"},
        {"name": "FILE_TYPE", "type": "VARCHAR(50)", "description": "Type of document (PDF, DOCX, etc)"},
        {"name": "CREATED_DATE", "type": "TIMESTAMP", "description": "Document creation date"},
        {"name": "MODIFIED_DATE", "type": "TIMESTAMP", "description": "Last modification date"},
        {"name": "AUTHOR", "type": "VARCHAR(100)", "description": "Document author"},
        {"name": "DEPARTMENT", "type": "VARCHAR(100)", "description": "Department owning the document"},
        {"name": "TAGS", "type": "VARCHAR(500)", "description": "Comma-separated tags"},
        {"name": "STATUS", "type": "VARCHAR(50)", "description": "Document status (ACTIVE, ARCHIVED, etc)"}
    ]
}

class FileMetadataService:
    def __init__(self):
        try:
            self.llm_service = LLMService()
            self.db_manager = TeradataManager()
            self.schema_prompt = self._format_schema_prompt()
        except Exception as e:
            logging.error(f"Failed to initialize FileMetadataService: {str(e)}")
            raise

    def _format_schema_prompt(self) -> str:
        """Format the schema into a prompt-friendly string"""
        try:
            prompt = f"Table Name: {DOCUMENT_SCHEMA['table_name']}\nColumns:\n"
            for col in DOCUMENT_SCHEMA['columns']:
                prompt += f"- {col['name']} ({col['type']}): {col['description']}\n"
            return prompt
        except Exception as e:
            logging.error(f"Failed to format schema prompt: {str(e)}")
            raise

    async def generate_sql_query(self, user_query: str) -> str:
        """Generate SQL query using LLM based on schema and user query"""
        try:
            prompt = f"""
            Based on the following table schema, generate a Teradata SQL query for this user request.
            
            {self.schema_prompt}
            
            User Query: {user_query}
            
            Return only the SQL query without any explanations.
            """
            return await self.llm_service.generate_response(prompt)
        except Exception as e:
            logging.error(f"Failed to generate SQL query: {str(e)}")
            raise

    def _format_results_for_llm(self, results: List[tuple], sql_query: str) -> str:
        """Convert database results to a readable format for LLM"""
        try:
            columns = [col["name"] for col in DOCUMENT_SCHEMA["columns"]]
            df = pd.DataFrame(results, columns=columns)
            data_str = df.to_string() if not df.empty else "No results found"
            
            return f"""
            SQL Query Executed: {sql_query}
            
            Query Results:
            {data_str}
            
            Please provide a natural language summary of these results.
            Focus on key information and any patterns or insights in the data.
            """
        except Exception as e:
            logging.error(f"Failed to format results for LLM: {str(e)}")
            raise

    async def _generate_human_readable_summary(self, results: List[tuple], sql_query: str) -> str:
        """Generate human-readable summary of results using LLM"""
        try:
            prompt = self._format_results_for_llm(results, sql_query)
            return await self.llm_service.generate_response(prompt)
        except Exception as e:
            logging.error(f"Failed to generate human readable summary: {str(e)}")
            raise

    async def validate_and_execute_query(self, sql_query: str, user_query: str) -> Dict[str, Any]:
        """Execute query and handle errors with LLM assistance"""
        try:
            try:
                results = await self.db_manager.execute_query_async(sql_query)
                summary = await self._generate_human_readable_summary(results, sql_query)
                
                return {
                    "status": "success",
                    "data": results,
                    "sql_query": sql_query,
                    "summary": summary,
                    "raw_data": results
                }
            except Exception as query_error:
                logging.error(f"Query execution failed: {str(query_error)}")
                error_prompt = f"""
                The SQL query failed with an error:
                
                Original Query: {sql_query}
                Schema: {self.schema_prompt}
                User Request: {user_query}
                Error: {str(query_error)}
                
                Please provide a corrected SQL query.
                """
                corrected_query = await self.llm_service.generate_response(error_prompt)
                return await self.validate_and_execute_query(corrected_query, user_query)
        except Exception as e:
            logging.error(f"Failed to validate and execute query: {str(e)}")
            raise

    async def get_metadata(self, user_query: str) -> Dict[str, Any]:
        """Main method to process user queries"""
        try:
            sql_query = await self.generate_sql_query(user_query)
            result = await self.validate_and_execute_query(sql_query, user_query)
            return result
        except Exception as e:
            logging.error(f"Query processing failed: {str(e)}")
            raise {
                "status": "error",
                "error": str(e),
                "query": user_query
            }
